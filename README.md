# Data Science Learning Path

This repository contains my learning path and resources for becoming a data scientist, focusing on deep learning, machine learning, data analysis, feature engineering, and statistics.

## Table of Contents

- [Phase 1: Foundations](#phase-1-foundations)
- [Phase 2: Data Analysis and Visualization](#phase-2-data-analysis-and-visualization)
- [Phase 3: Machine Learning](#phase-3-machine-learning)
- [Phase 4: Feature Engineering](#phase-4-feature-engineering)
- [Phase 5: Deep Learning](#phase-5-deep-learning)
- [Phase 6: Advanced Statistics](#phase-6-advanced-statistics)
- [Phase 7: Big Data Technologies](#phase-7-big-data-technologies)
- [Phase 8: Practical Projects and Portfolio Building](#phase-8-practical-projects-and-portfolio-building)

## Phase 1: Foundations

### 1. Mathematics for Machine Learning

#### a. Linear Algebra
- Vectors and matrices
- Matrix operations (addition, multiplication, transposition)
- Eigenvalues and eigenvectors
- Vector spaces and linear transformations
- Singular Value Decomposition (SVD)

#### b. Calculus
- Limits and continuity
- Derivatives and partial derivatives
- Integrals
- Gradient, Hessian, and Laplacian
- Optimization techniques (gradient descent)

#### c. Probability Theory
- Basic probability concepts
- Random variables and probability distributions
- Conditional probability and Bayes' theorem
- Expectation, variance, and covariance
- Central Limit Theorem

#### d. Statistics
- Descriptive statistics (mean, median, mode, standard deviation)
- Inferential statistics
- Hypothesis testing
- Confidence intervals
- p-values and statistical significance

### 2. Programming Skills

#### a. Python basics
- Data types and structures
- Control flow (if-else, loops)
- Functions and modules
- Object-oriented programming
- File I/O operations

#### b. Data structures and algorithms
- Arrays and linked lists
- Stacks and queues
- Trees and graphs
- Sorting and searching algorithms
- Time and space complexity analysis

## Phase 2: Data Analysis and Visualization

### 1. Data Analysis

#### a. Pandas
- DataFrame and Series objects
- Data loading and saving
- Data manipulation (filtering, sorting, grouping)
- Merging and joining datasets
- Handling missing data

#### b. NumPy
- Arrays and array operations
- Broadcasting
- Vectorization
- Random number generation

#### c. Data cleaning and preprocessing
- Handling missing values
- Outlier detection and treatment
- Data normalization and standardization
- Encoding categorical variables
- Feature scaling

### 2. Data Visualization

#### a. Matplotlib
- Basic plots (line, scatter, bar, histogram)
- Customizing plots (colors, labels, legends)
- Subplots and multiple plots

#### b. Seaborn
- Statistical plots (box plots, violin plots)
- Heatmaps and correlation matrices
- Pair plots and joint plots

#### c. Plotly
- Interactive plots
- Dashboards
- 3D visualizations

### 3. SQL for Data Science
- Relational database concepts
- Basic SQL queries (SELECT, WHERE, GROUP BY, JOIN)
- Subqueries and CTEs
- Window functions
- Database design and normalization

## Phase 3: Machine Learning

### 1. Supervised Learning

#### a. Linear Regression
- Simple and multiple linear regression
- Gradient descent for linear regression
- Regularization (L1 and L2)

#### b. Logistic Regression
- Binary and multiclass logistic regression
- Maximum likelihood estimation
- ROC curve and AUC

#### c. Decision Trees and Random Forests
- Decision tree construction algorithms (ID3, C4.5, CART)
- Pruning techniques
- Random forest algorithm
- Feature importance

#### d. Support Vector Machines
- Linear and non-linear SVMs
- Kernel trick
- Soft margin classification

#### e. Naive Bayes
- Gaussian Naive Bayes
- Multinomial Naive Bayes
- Bernoulli Naive Bayes

### 2. Unsupervised Learning

#### a. K-means clustering
- K-means algorithm
- Elbow method for choosing K
- Silhouette analysis

#### b. Hierarchical clustering
- Agglomerative and divisive clustering
- Linkage methods
- Dendrogram interpretation

#### c. Principal Component Analysis (PCA)
- Eigendecomposition
- Explained variance ratio
- Dimensionality reduction techniques

### 3. Ensemble Methods

#### a. Bagging and Boosting
- Bootstrap aggregating (Bagging)
- AdaBoost
- Gradient Boosting

#### b. XGBoost, LightGBM
- XGBoost algorithm
- LightGBM algorithm
- Hyperparameter tuning for boosting algorithms

### 4. Model Evaluation and Validation

#### a. Cross-validation
- K-fold cross-validation
- Stratified K-fold cross-validation
- Leave-one-out cross-validation

#### b. Hyperparameter tuning
- Grid search
- Random search
- Bayesian optimization

## Phase 4: Feature Engineering

### 1. Feature Selection Techniques
- Filter methods (correlation, chi-squared)
- Wrapper methods (recursive feature elimination)
- Embedded methods (Lasso, Ridge regression)

### 2. Feature Extraction Methods
- Principal Component Analysis (PCA)
- Linear Discriminant Analysis (LDA)
- t-SNE

### 3. Dimensionality Reduction Techniques
- Autoencoders
- UMAP (Uniform Manifold Approximation and Projection)

## Phase 5: Deep Learning

### 1. Neural Networks Basics
- Perceptrons and multilayer perceptrons
- Activation functions
- Backpropagation
- Optimization algorithms (SGD, Adam, RMSprop)

### 2. Convolutional Neural Networks (CNN)
- Convolutional layers
- Pooling layers
- Popular CNN architectures (VGG, ResNet, Inception)
- Transfer learning with CNNs

### 3. Recurrent Neural Networks (RNN) and LSTM
- RNN architecture
- Vanishing gradient problem
- LSTM and GRU cells
- Sequence-to-sequence models

### 4. Generative Adversarial Networks (GAN)
- Generator and discriminator networks
- GAN training process
- Variations of GANs (DCGAN, CycleGAN)

### 5. Transfer Learning
- Fine-tuning pre-trained models
- Feature extraction
- Domain adaptation

### 6. Deep Learning Frameworks

#### a. TensorFlow
- TensorFlow basics
- Keras API
- TensorFlow 2.x features

#### b. PyTorch
- PyTorch basics
- Autograd
- nn.Module and neural network layers

## Phase 6: Advanced Statistics

### 1. Hypothesis Testing
- t-tests
- ANOVA
- Chi-squared tests
- Non-parametric tests

### 2. Bayesian Statistics
- Bayesian inference
- Prior and posterior distributions
- Markov Chain Monte Carlo (MCMC)

### 3. Time Series Analysis
- Stationarity and differencing
- ARIMA models
- Seasonal decomposition
- Prophet

### 4. A/B Testing
- Experimental design for A/B tests
- Sample size calculation
- Statistical significance in A/B testing

### 5. Experimental Design
- Factorial designs
- Randomized controlled trials
- Power analysis

## Phase 7: Big Data Technologies

### 1. Hadoop Ecosystem
- HDFS
- MapReduce
- YARN
- Hive and Pig

### 2. Apache Spark
- RDDs
- Spark SQL
- Spark MLlib
- Spark Streaming

### 3. Distributed Computing Concepts
- Parallel processing
- Data partitioning
- Fault tolerance
- CAP theorem

## Phase 8: Practical Projects and Portfolio Building

### 1. Kaggle Competitions
- Participate in various competitions
- Learn from top solutions
- Collaborate with other data scientists

### 2. Personal Projects
- Develop end-to-end machine learning projects
- Work on diverse problem domains
- Implement production-ready solutions

### 3. Creating a GitHub portfolio
- Version control with Git
- Documenting projects
- Sharing code and notebooks

(Add your chosen license here)
